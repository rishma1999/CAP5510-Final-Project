{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6AqiX48k_dy",
        "outputId": "6411572a-7145-4391-f42a-c0ff5341911c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Starting Analysis for: Top 50 (Input Size: 50)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "   CNC Top 50: 100%|██████████| 10/10 [00:12<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Starting Analysis for: Top 100 (Input Size: 100)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "   CNC Top 100: 100%|██████████| 10/10 [00:06<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Starting Analysis for: Top 250 (Input Size: 250)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "   CNC Top 250: 100%|██████████| 10/10 [00:06<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Starting Analysis for: All Genes (Input Size: 7129)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "   CNC All Genes: 100%|██████████| 10/10 [00:34<00:00,  3.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "======================================================================\n",
            "FINAL MLP AND CNC DIMENSIONALITY REDUCTION IMPACT COMPARISON\n",
            "======================================================================\n",
            "| Feature Set   | Model Type   |   Accuracy |   F1-Score |   ROC-AUC |\n",
            "|:--------------|:-------------|-----------:|-----------:|----------:|\n",
            "| Top 50        | Single MLP   |   0.8      |   0.571429 |      0.8  |\n",
            "| Top 50        | Diverse CNC  |   0.8      |   0.571429 |      0.86 |\n",
            "| Top 100       | Single MLP   |   0.933333 |   0.888889 |      0.86 |\n",
            "| Top 100       | Diverse CNC  |   0.933333 |   0.888889 |      0.88 |\n",
            "| Top 250       | Single MLP   |   0.933333 |   0.888889 |      0.96 |\n",
            "| Top 250       | Diverse CNC  |   0.933333 |   0.888889 |      0.96 |\n",
            "| All Genes     | Single MLP   |   0.933333 |   0.888889 |      0.98 |\n",
            "| All Genes     | Diverse CNC  |   0.933333 |   0.888889 |      0.96 |\n",
            "======================================================================\n",
            "\n",
            "------------------------------------------------------------\n",
            "CONFUSION MATRIX: Single MLP on Top 50\n",
            "Accuracy: 0.8000 | ROC-AUC: 0.8000\n",
            "------------------------------------------------------------\n",
            "           Predicted 0 | Predicted 1\n",
            "   True 0:          10 |          0 (TN | FP)\n",
            "   True 1:           3 |          2 (FN | TP)\n",
            "------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------\n",
            "CONFUSION MATRIX: Diverse CNC on Top 50\n",
            "Accuracy: 0.8000 | ROC-AUC: 0.8600\n",
            "------------------------------------------------------------\n",
            "           Predicted 0 | Predicted 1\n",
            "   True 0:          10 |          0 (TN | FP)\n",
            "   True 1:           3 |          2 (FN | TP)\n",
            "------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------\n",
            "CONFUSION MATRIX: Single MLP on Top 100\n",
            "Accuracy: 0.9333 | ROC-AUC: 0.8600\n",
            "------------------------------------------------------------\n",
            "           Predicted 0 | Predicted 1\n",
            "   True 0:          10 |          0 (TN | FP)\n",
            "   True 1:           1 |          4 (FN | TP)\n",
            "------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------\n",
            "CONFUSION MATRIX: Diverse CNC on Top 100\n",
            "Accuracy: 0.9333 | ROC-AUC: 0.8800\n",
            "------------------------------------------------------------\n",
            "           Predicted 0 | Predicted 1\n",
            "   True 0:          10 |          0 (TN | FP)\n",
            "   True 1:           1 |          4 (FN | TP)\n",
            "------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------\n",
            "CONFUSION MATRIX: Single MLP on Top 250\n",
            "Accuracy: 0.9333 | ROC-AUC: 0.9600\n",
            "------------------------------------------------------------\n",
            "           Predicted 0 | Predicted 1\n",
            "   True 0:          10 |          0 (TN | FP)\n",
            "   True 1:           1 |          4 (FN | TP)\n",
            "------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------\n",
            "CONFUSION MATRIX: Diverse CNC on Top 250\n",
            "Accuracy: 0.9333 | ROC-AUC: 0.9600\n",
            "------------------------------------------------------------\n",
            "           Predicted 0 | Predicted 1\n",
            "   True 0:          10 |          0 (TN | FP)\n",
            "   True 1:           1 |          4 (FN | TP)\n",
            "------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------\n",
            "CONFUSION MATRIX: Single MLP on All Genes\n",
            "Accuracy: 0.9333 | ROC-AUC: 0.9800\n",
            "------------------------------------------------------------\n",
            "           Predicted 0 | Predicted 1\n",
            "   True 0:          10 |          0 (TN | FP)\n",
            "   True 1:           1 |          4 (FN | TP)\n",
            "------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------\n",
            "CONFUSION MATRIX: Diverse CNC on All Genes\n",
            "Accuracy: 0.9333 | ROC-AUC: 0.9600\n",
            "------------------------------------------------------------\n",
            "           Predicted 0 | Predicted 1\n",
            "   True 0:          10 |          0 (TN | FP)\n",
            "   True 1:           1 |          4 (FN | TP)\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "======================================================================\n",
            "STATISTICAL VALIDATION (McNEMAR'S TEST)\n",
            "Comparing the BEST performing MLP vs. BEST performing CNC.\n",
            "Best MLP (AUC 0.9800) on All Genes\n",
            "Best CNC (AUC 0.9600) on Top 250\n",
            "======================================================================\n",
            "McNEMAR's EXACT TEST RESULTS (n=0)\n",
            "----------------------------------------\n",
            "  MLP Correct, CNC Incorrect (a): 0\n",
            "  CNC Correct, MLP Incorrect (b): 0\n",
            "----------------------------------------\n",
            "  P-value: 2.0000\n",
            "\n",
            "Interpretation:\n",
            "The difference in performance between the two models is NOT statistically significant (p > 0.05).\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from scipy.stats import binom\n",
        "\n",
        "# Set seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# --- Configuration & Hyperparameters (Retained from previous steps) ---\n",
        "NUM_CLASSES = 1\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 16\n",
        "NUM_COMMITTEE_MEMBERS = 10\n",
        "HIDDEN_ARCHITECTURES = [\n",
        "    (64, 32, 0.5), (128, 64, 0.4), (32, 16, 0.6), (96, 48, 0.55), (160, 80, 0.3)\n",
        "]\n",
        "FEATURE_SETS_MAP = {\n",
        "    'Top 50': {'X_train': 'X_train_top50.csv', 'y_train': 'y_train50.csv', 'X_test': 'X_test_top50.csv', 'y_test': 'y_test50.csv'},\n",
        "    'Top 100': {'X_train': 'X_train_top100.csv', 'y_train': 'y_train100.csv', 'X_test': 'X_test_top100.csv', 'y_test': 'y_test100.csv'},\n",
        "    'Top 250': {'X_train': 'X_train_top250.csv', 'y_train': 'y_train250.csv', 'X_test': 'X_test_top250.csv', 'y_test': 'y_test250.csv'},\n",
        "    'All Genes': {'X_train': 'X_train_all.csv', 'y_train': 'y_train_all.csv', 'X_test': 'X_test_all.csv', 'y_test': 'y_test_all.csv'}\n",
        "}\n",
        "\n",
        "\n",
        "# --- 1. MLP Model Definition and Helper Functions ---\n",
        "\n",
        "class SimpleMLP(nn.Module):\n",
        "    # MLP definition remains the same\n",
        "    def __init__(self, input_size, h1_size, h2_size, num_classes, dropout_rate):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.layer_1 = nn.Linear(input_size, h1_size)\n",
        "        self.layer_2 = nn.Linear(h1_size, h2_size)\n",
        "        self.layer_out = nn.Linear(h2_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x); x = self.relu(x); x = self.dropout(x)\n",
        "        x = self.layer_2(x); x = self.relu(x)\n",
        "        x = self.layer_out(x); x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "def train_model(model, train_loader, epochs, lr):\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(inputs), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return model\n",
        "\n",
        "def evaluate_raw_outputs(y_test_np, raw_outputs):\n",
        "    \"\"\"Calculates metrics based on raw outputs (used by both MLP and CNC).\"\"\"\n",
        "    predictions = (raw_outputs >= 0.5).astype(int)\n",
        "    y_true = y_test_np.flatten().astype(int)\n",
        "\n",
        "    acc = accuracy_score(y_true, predictions)\n",
        "    f1 = f1_score(y_true, predictions, average='binary')\n",
        "    auc = roc_auc_score(y_true, raw_outputs)\n",
        "\n",
        "    return {'Accuracy': acc, 'F1-Score': f1, 'ROC-AUC': auc, 'Predictions': predictions, 'TrueLabels': y_true}\n",
        "\n",
        "# --- 2. Statistical Testing Function ---\n",
        "\n",
        "def mcnemar_test(y_true, pred1, pred2):\n",
        "    \"\"\"\n",
        "    Performs McNemar's test to compare two classifiers (Model 1 and Model 2).\n",
        "    H0: The two classifiers have the same error rate.\n",
        "    \"\"\"\n",
        "    # a: samples correctly predicted by M1 but incorrectly by M2\n",
        "    # b: samples correctly predicted by M2 but incorrectly by M1\n",
        "\n",
        "    y_true = y_true.flatten()\n",
        "\n",
        "    # 1. Check where predictions differ\n",
        "    correct1 = (y_true == pred1)\n",
        "    correct2 = (y_true == pred2)\n",
        "\n",
        "    # Calculate disagree counts (a and b)\n",
        "    a = np.sum(np.logical_and(correct1, np.logical_not(correct2))) # M1 correct, M2 incorrect\n",
        "    b = np.sum(np.logical_and(correct2, np.logical_not(correct1))) # M2 correct, M1 incorrect\n",
        "\n",
        "    # McNemar's Test (using binomial exact test for small sample sizes)\n",
        "    # The statistic follows B(n, 0.5) where n = a + b\n",
        "    n = a + b\n",
        "\n",
        "    # Calculate p-value: probability of observing a count of a or more extreme (2-sided test)\n",
        "    # The test compares min(a, b) to n/2\n",
        "    min_count = min(a, b)\n",
        "    p_value = 2.0 * binom.cdf(min_count, n, 0.5)\n",
        "\n",
        "    return {'a': a, 'b': b, 'n': n, 'p_value': p_value}\n",
        "\n",
        "# --- 3. Model Training Functions (Modified to return predictions) ---\n",
        "\n",
        "def load_data_for_comparison(X_train_path, y_train_path, X_test_path, y_test_path):\n",
        "    \"\"\"Loads all tensors and determines input size for a specific feature set.\"\"\"\n",
        "    try:\n",
        "        X_train_df = pd.read_csv(X_train_path)\n",
        "        y_train_df = pd.read_csv(y_train_path)\n",
        "        X_test_df = pd.read_csv(X_test_path)\n",
        "        y_test_df = pd.read_csv(y_test_path)\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: {e}. Skipping this feature set.\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    INPUT_SIZE = X_train_df.shape[1]\n",
        "    y_train_col = y_train_df.columns[0]\n",
        "    y_test_col = y_test_df.columns[0]\n",
        "\n",
        "    X_train = torch.tensor(X_train_df.values, dtype=torch.float32)\n",
        "    y_train = torch.tensor(y_train_df[y_train_col].values, dtype=torch.float32).unsqueeze(1)\n",
        "    X_test = torch.tensor(X_test_df.values, dtype=torch.float32)\n",
        "    y_test_np = y_test_df[y_test_col].values.reshape(-1, 1)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    return INPUT_SIZE, X_train, y_train, X_test, y_test_np, train_loader\n",
        "\n",
        "def train_and_evaluate_mlp(INPUT_SIZE, train_loader, X_test, y_test_np, feature_set_name):\n",
        "    \"\"\"Trains and evaluates a single baseline MLP.\"\"\"\n",
        "    h1, h2, dropout_rate = HIDDEN_ARCHITECTURES[0]\n",
        "    mlp_model = SimpleMLP(INPUT_SIZE, h1, h2, NUM_CLASSES, dropout_rate)\n",
        "    mlp_model = train_model(mlp_model, train_loader, NUM_EPOCHS, LEARNING_RATE)\n",
        "\n",
        "    mlp_model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = mlp_model(X_test).squeeze().numpy()\n",
        "\n",
        "    metrics = evaluate_raw_outputs(y_test_np, outputs)\n",
        "    metrics['Model Type'] = 'Single MLP'\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def train_and_evaluate_cnc(INPUT_SIZE, X_train, y_train, X_test, y_test_np, feature_set_name):\n",
        "    \"\"\"Trains and evaluates the Diverse CNC.\"\"\"\n",
        "    num_train_samples = X_train.shape[0]\n",
        "    num_architectures = len(HIDDEN_ARCHITECTURES)\n",
        "    all_member_outputs = []\n",
        "\n",
        "    # Training Diverse CNC\n",
        "    for i in tqdm(range(NUM_COMMITTEE_MEMBERS), desc=f\"   CNC {feature_set_name}\"):\n",
        "        bootstrap_indices = np.random.choice(range(num_train_samples), size=num_train_samples, replace=True)\n",
        "        X_boot = X_train[bootstrap_indices]\n",
        "        y_boot = y_train[bootstrap_indices]\n",
        "        boot_dataset = TensorDataset(X_boot, y_boot)\n",
        "        boot_train_loader = DataLoader(boot_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "        h1, h2, dropout_rate = HIDDEN_ARCHITECTURES[i % num_architectures]\n",
        "        member_model = SimpleMLP(INPUT_SIZE, h1, h2, NUM_CLASSES, dropout_rate)\n",
        "        member_model = train_model(member_model, boot_train_loader, NUM_EPOCHS, LEARNING_RATE)\n",
        "\n",
        "        member_model.eval()\n",
        "        with torch.no_grad():\n",
        "            member_outputs = member_model(X_test).squeeze().numpy()\n",
        "            all_member_outputs.append(member_outputs)\n",
        "\n",
        "    # Combine Predictions (Averaging)\n",
        "    combined_outputs = np.stack(all_member_outputs, axis=0).mean(axis=0)\n",
        "\n",
        "    # Evaluate\n",
        "    metrics = evaluate_raw_outputs(y_test_np, combined_outputs)\n",
        "    metrics['Model Type'] = 'Diverse CNC'\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# --- 4. Final Reporting Functions ---\n",
        "\n",
        "def report_results_and_confusion(results_df):\n",
        "    \"\"\"Prints the final summary and generates confusion matrices for ALL data points.\"\"\"\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*70)\n",
        "    print(\"FINAL MLP AND CNC DIMENSIONALITY REDUCTION IMPACT COMPARISON\")\n",
        "    print(\"=\"*70)\n",
        "    print(results_df[['Feature Set', 'Model Type', 'Accuracy', 'F1-Score', 'ROC-AUC']].to_markdown(index=False))\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Print Confusion Matrix for every result (for detailed reporting)\n",
        "    for index, row in results_df.iterrows():\n",
        "        y_true = row['TrueLabels']\n",
        "        predictions = row['Predictions']\n",
        "        cm = confusion_matrix(y_true, predictions)\n",
        "\n",
        "        print(\"\\n\" + \"-\"*60)\n",
        "        print(f\"CONFUSION MATRIX: {row['Model Type']} on {row['Feature Set']}\")\n",
        "        print(f\"Accuracy: {row['Accuracy']:.4f} | ROC-AUC: {row['ROC-AUC']:.4f}\")\n",
        "        print(\"-\"*60)\n",
        "        print(\"           Predicted 0 | Predicted 1\")\n",
        "        print(f\"   True 0:  {cm[0, 0]:>10} | {cm[0, 1]:>10} (TN | FP)\")\n",
        "        print(f\"   True 1:  {cm[1, 0]:>10} | {cm[1, 1]:>10} (FN | TP)\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "# --- 5. Main Execution ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    comparison_results = []\n",
        "    best_results = {}\n",
        "\n",
        "    for name, paths in FEATURE_SETS_MAP.items():\n",
        "\n",
        "        INPUT_SIZE, X_train, y_train, X_test, y_test_np, train_loader = load_data_for_comparison(\n",
        "            paths['X_train'], paths['y_train'], paths['X_test'], paths['y_test']\n",
        "        )\n",
        "\n",
        "        if INPUT_SIZE is None:\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n{'='*70}\\nStarting Analysis for: {name} (Input Size: {INPUT_SIZE})\\n{'='*70}\")\n",
        "\n",
        "        # Run Single MLP\n",
        "        mlp_metrics = train_and_evaluate_mlp(INPUT_SIZE, train_loader, X_test, y_test_np, name)\n",
        "        mlp_metrics['Feature Set'] = name\n",
        "        comparison_results.append(mlp_metrics)\n",
        "        if mlp_metrics['ROC-AUC'] > best_results.get('MLP', {'ROC-AUC': 0})['ROC-AUC']:\n",
        "            best_results['MLP'] = mlp_metrics\n",
        "\n",
        "        # Run Diverse CNC\n",
        "        cnc_metrics = train_and_evaluate_cnc(INPUT_SIZE, X_train, y_train, X_test, y_test_np, name)\n",
        "        cnc_metrics['Feature Set'] = name\n",
        "        comparison_results.append(cnc_metrics)\n",
        "        if cnc_metrics['ROC-AUC'] > best_results.get('CNC', {'ROC-AUC': 0})['ROC-AUC']:\n",
        "            best_results['CNC'] = cnc_metrics\n",
        "\n",
        "    # Consolidate results and save\n",
        "    results_df = pd.DataFrame(comparison_results)\n",
        "    results_df.to_csv('mlp_cnc_dimensionality_comparison_full.csv', index=False)\n",
        "\n",
        "    # Final Reporting (Metrics & Confusion Matrices)\n",
        "    report_results_and_confusion(results_df)\n",
        "\n",
        "    # --- 6. Statistical Validation on Best Models ---\n",
        "\n",
        "    print(\"\\n\\n\" + \"=\"*70)\n",
        "    print(\"STATISTICAL VALIDATION (McNEMAR'S TEST)\")\n",
        "    print(\"Comparing the BEST performing MLP vs. BEST performing CNC.\")\n",
        "    print(f\"Best MLP (AUC {best_results['MLP']['ROC-AUC']:.4f}) on {best_results['MLP']['Feature Set']}\")\n",
        "    print(f\"Best CNC (AUC {best_results['CNC']['ROC-AUC']:.4f}) on {best_results['CNC']['Feature Set']}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Use the raw predictions from the best models found\n",
        "    y_true = best_results['MLP']['TrueLabels'] # True labels are the same across all experiments (only test data changed)\n",
        "    pred_mlp = best_results['MLP']['Predictions']\n",
        "    pred_cnc = best_results['CNC']['Predictions']\n",
        "\n",
        "    stat_result = mcnemar_test(y_true, pred_mlp, pred_cnc)\n",
        "\n",
        "    print(f\"McNEMAR's EXACT TEST RESULTS (n={stat_result['n']})\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"  MLP Correct, CNC Incorrect (a): {stat_result['a']}\")\n",
        "    print(f\"  CNC Correct, MLP Incorrect (b): {stat_result['b']}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"  P-value: {stat_result['p_value']:.4f}\")\n",
        "    print(\"\\nInterpretation:\")\n",
        "    if stat_result['p_value'] < 0.05:\n",
        "        print(\"The difference in performance between the two models is statistically significant (p < 0.05).\")\n",
        "    else:\n",
        "        print(\"The difference in performance between the two models is NOT statistically significant (p > 0.05).\")\n",
        "    print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxPXJXsmnuNw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}